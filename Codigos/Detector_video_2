#include <iostream>
#include <opencv2/opencv.hpp>
#include <torch/script.h>
#include <torch/torch.h>

using namespace cv;
using namespace std;

int main() {
    // Modelo YOLOv5 cargado desde un archivo ONNX
    torch::jit::script::Module model = torch::jit::load("best.onnx");

    // Directorios de videos
    string path_dirs_videos = "/media/gpu";
    vector<string> dir_videos = os::listdir(path_dirs_videos);
    string path_video = "";

    // Máscara para detección de cuerpos en movimiento
    Ptr<BackgroundSubtractorMOG2> detection = cv::createBackgroundSubtractorMOG2(10000, 12, false);

    // Zona de detección de movimientos
    int y1_mov = 200;
    int y2_mov = 250;
    int x1_mov = 350;
    int x2_mov = 750;

    // Área de detección de chapas
    int y1 = 250;
    int y2 = 560;
    int x1 = 350;
    int x2 = 1085;
    
    // Ruteado a directorios de videos
    for (const auto& dir : dir_videos) {
        vector<string> path_videos = os::listdir(path_dirs_videos + "/" + dir);
        for (const auto& video : path_videos) {
            path_video = path_dirs_videos + "/" + dir + "/" + video;
            vector<string> extencion = split(video, ".");
            if (extencion[1] == "mp4") {
                VideoCapture capture(path_video);
                vector<string> lecturas;

                // Bucle de detección de Chapas
                while (capture.isOpened()) {
                    // Leemos frame a frame
                    Mat frame;
                    capture >> frame;
                    if (frame.empty())
                        break;
                    
                    // Rectángulo en Área de interés
                    rectangle(frame, Point(x1, y1), Point(x2, y2), Scalar(0, 255, 0), 2);
                    
                    // Recortamos Área de interés
                    Mat recorte_det = frame(Rect(x1, y1, x2 - x1, y2 - y1));
                    Mat recorte_mov = frame(Rect(x1_mov, y1_mov, x2_mov - x1_mov, y2_mov - y1_mov));
                    
                    // Aplicamos la máscara de detección de movimiento en el recorte
                    Mat mascara;
                    detection->apply(recorte_mov, mascara);
                    threshold(mascara, mascara, 254, 255, THRESH_BINARY);
                    
                    vector<vector<Point>> contornos;
                    findContours(mascara, contornos, RETR_TREE, CHAIN_APPROX_SIMPLE);
                    
                    for (const auto& contorno : contornos) {
                        double area = contourArea(contorno);
                        if (area > 5000) {
                            // Aquí hacemos la detección
                            torch::Tensor results = model(recorte_det);
                            try {
                                torch::Tensor coor = results[0]["box"];
                                int chapax1 = round(coor[0].item().toFloat());
                                int chapay1 = round(coor[1].item().toFloat());
                                int chapax2 = round(coor[2].item().toFloat());
                                int chapay2 = round(coor[3].item().toFloat());
                                
                                // Recortamos el contorno de la placa
                                Mat placa = frame(Rect(x1 + chapax1, y1 + chapay1, chapax2 - chapax1, chapay2 - chapay1));
                                
                                // Dibujamos el contorno de la placa en el frame
                                rectangle(frame, Point(x1 + chapax1, y1 + chapay1), Point(x1 + chapax2, y1 + chapay2), Scalar(0, 255, 0), 2);
                                
                                // AQUÍ HACEMOS LA LECTURA DE LA CHAPA
                                string chapa = "CHAPA"; // Suponiendo que se realiza la lectura de la chapa
                                
                                // Mostramos el Frame con la chapa enmarcada
                                imshow("Detector de Chapas", frame);
                                
                                if (chapa[1] <= 0.85)
                                    lecturas.push_back(chapa);
                            } catch (...) {
                                // Mostramos el Frame Sin Chapa detectada
                                imshow("Detector de Chapas", frame);
                                
                                if (!lecturas.empty()) {
                                    string max = lecturas[0];
                                    for (const auto& lectura : lecturas) {
                                        if (lectura[1] > max[1])
                                            max = lectura;
                                    }
                                    ofstream file;
                                    file.open("Registros.txt", ios::app);
                                    file << max << "," << video;
                                    file.close();
                                    lecturas.clear();
                                }
                            }
                        }
                    }
                    int t = waitKey(1);
                    if (t == 27)
                        break;
                }
            }
        }
    }
    return 0;
}
